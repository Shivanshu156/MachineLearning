{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8496207-6aa3-415d-99b8-b13056933e1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 23:13:40.057908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-17 23:13:40.191050: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-17 23:13:40.196959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-17 23:13:40.196981: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-17 23:13:40.226647: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-17 23:13:40.922030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-17 23:13:40.922113: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-17 23:13:40.922122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 989998\n",
      "Number of unique input tokens: 43\n",
      "Number of unique output tokens: 43\n",
      "Max sequence length for inputs: 32\n",
      "Max sequence length for outputs: 32\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import re\n",
    "from typing import Tuple\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "max_sequence_len = 32\n",
    "batch_size = 512  # Batch size for training.\n",
    "epochs = 5  # Number of epochs to train for.\n",
    "latent_dim = 1024  # Latent dimensionality of the encoding space.\n",
    "num_samples = 990000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "filepath = \"sample_train.txt\"\n",
    "\n",
    "functions = []\n",
    "derivatives = []\n",
    "input_characters = set()\n",
    "# target_characters = set()\n",
    "with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in list(filter(None,lines[: min(num_samples, len(lines) - 1)])):\n",
    "    function, derivative = line.split(\"=\")\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    derivative = \"\\t\" + derivative + \"\\n\"\n",
    "    functions.append(function)\n",
    "    derivatives.append(derivative)\n",
    "    for char in list(filter(None, re.split(r\"(exp|sin|cos|\\^|\\/|[a-zA-Z]|[0-9]|[()]|\\+|\\-|\\*|\\#)\", function))):\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    # for char in target_text:\n",
    "    #     if char not in target_characters:\n",
    "    #         target_characters.add(char)\n",
    "\n",
    "\n",
    "input_characters.add('\\n')\n",
    "input_characters.add('\\t')\n",
    "input_characters.add('')\n",
    "input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(functions))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_encoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_sequence_len)\n",
    "print(\"Max sequence length for outputs:\", max_sequence_len)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a90fb3-68c1-4ebb-b784-45da867e443f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature vectors created successfully!!\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(functions), max_sequence_len, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(functions), max_sequence_len, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(functions), max_sequence_len, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (function, derivative) in enumerate(zip(functions, derivatives)):\n",
    "    for t, char in enumerate(list(filter(None,re.split(r\"(exp|sin|cos|\\^|\\/|[a-zA-Z]|[0-9]|[()]|\\+|\\-|\\*|\\#|\\n|\\t)\", function)))):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index['']] = 1.0\n",
    "    for t, char in enumerate(list(filter(None,re.split(r\"(exp|sin|cos|\\^|\\/|[a-zA-Z]|[0-9]|[()]|\\+|\\-|\\*|\\#|\\n|\\t)\", derivative)))):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, input_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, input_token_index['']] = 1.0\n",
    "    decoder_target_data[i, t:, input_token_index['']] = 1.0\n",
    "print('Input feature vectors created successfully!!')\n",
    "\n",
    "# print(decoder_input_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859f4ee3-f758-4367-b233-35bb8420d2d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 23:14:19.212836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-17 23:14:19.212880: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-17 23:14:19.212897: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (python-20220917-002439): /proc/driver/nvidia/version does not exist\n",
      "2022-09-17 23:14:19.213156: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "model = keras.models.load_model(\"s2s_990000_latent_1024\")\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = model.input[0]\n",
    "# encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = model.layers[2].output\n",
    "# del encoder_outputs\n",
    "# gc.collect()\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = model.input[1]\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# Retrieve the config\n",
    "# config = model.get_config()\n",
    "\n",
    "# # At loading time, register the custom objects with a `custom_object_scope`:\n",
    "# custom_objects = {\"custom_loss_fuction\": custom_loss_function}\n",
    "# with keras.utils.custom_object_scope(custom_objects):\n",
    "#     model = keras.Model.from_config(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bb9609-a761-4e82-96d7-4a64e0d4803b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1547/1547 [==============================] - 3875s 3s/step - loss: 4.1669e-04 - accuracy: 0.9876 - precision: 0.9944 - val_loss: 2.8531e-04 - val_accuracy: 0.9919 - val_precision: 0.9952\n",
      "Epoch 2/5\n",
      "1547/1547 [==============================] - 3979s 3s/step - loss: 2.0990e-04 - accuracy: 0.9941 - precision: 0.9965 - val_loss: 1.7650e-04 - val_accuracy: 0.9950 - val_precision: 0.9970\n",
      "Epoch 3/5\n",
      "  78/1547 [>.............................] - ETA: 58:11 - loss: 1.5686e-04 - accuracy: 0.9956 - precision: 0.9974"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_24611/4058395596.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m )\n\u001B[1;32m     25\u001B[0m \u001B[0;31m# Save model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1562\u001B[0m                         ):\n\u001B[1;32m   1563\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1564\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1565\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1566\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    916\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    945\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    946\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 947\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    948\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2495\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   2496\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 2497\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   2498\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2499\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1861\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1862\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1863\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1864\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1865\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    502\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    505\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 55\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     56\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    loss = tf.reduce_mean(squared_difference, axis=-1)\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + keras.backend.epsilon())\n",
    "    return precision_keras\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=custom_loss_function, metrics=[\"accuracy\", precision]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s_990000_latent_1024_tune_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b8c33a-e9e6-438c-b66e-e480de002890",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_990000_latent_1024_tune_precision/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_990000_latent_1024_tune_precision/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"s2s_990000_latent_1024_tune_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e8231e-a61d-42e4-9164-532ecbe9918f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 1000\n",
      "Feature vectors for test sample created successfully!!\n"
     ]
    }
   ],
   "source": [
    "filepath_test = \"sample_test.txt\"\n",
    "num_samples_test = 1000\n",
    "functions_test = []\n",
    "derivatives_test = []\n",
    "with open(filepath_test, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in list(filter(None,lines[: min(num_samples_test, len(lines) - 1)])):\n",
    "    function, derivative = line.split(\"=\")\n",
    "    functions_test.append(function)\n",
    "    derivatives_test.append(derivative)\n",
    "\n",
    "print(\"Number of test samples:\", len(functions_test))\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "\n",
    "encoder_input_data_test = np.zeros(\n",
    "    (len(functions_test), max_sequence_len, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (function, derivative) in enumerate(zip(functions_test, derivatives_test)):\n",
    "    for t, char in enumerate(list(filter(None,re.split(r\"(exp|sin|cos|\\^|\\/|[a-zA-Z]|[0-9]|[()]|\\+|\\-|\\*|\\#|\\n|\\t)\", function)))):\n",
    "            encoder_input_data_test[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data_test[i, t + 1 :, input_token_index['']] = 1.0\n",
    "    \n",
    "print('Feature vectors for test sample created successfully!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f9b324-9c73-465d-82be-a35a7e48e74d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all prediction vectors are set after loading the model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Run inference (sampling)\n",
    "1. encode input and retrieve initial decoder state\n",
    "2. run one step of decoder with this initial state\n",
    "and a \"start of sequence\" token as target.\n",
    "Output will be the next target token.\n",
    "3. Repeat with the current target token and current states\n",
    "\"\"\"\n",
    "\n",
    "# At loading time, register the custom objects with a `custom_object_scope`:\n",
    "custom_objects = {\"custom_loss_fuction\": custom_loss_function, \"precision\": precision}\n",
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"s2s_990000_latent_1024_tune_precision\", custom_objects=custom_objects, compile=False)\n",
    "# Retrieve the config\n",
    "# config = model.get_config()\n",
    "\n",
    "\n",
    "# with keras.utils.custom_object_scope(custom_objects):\n",
    "#     model = keras.Model.from_config(config)\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=custom_loss_function, metrics=[\"accuracy\"]\n",
    ")\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "print(\"all prediction vectors are set after loading the model\")\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_encoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, input_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_sequence_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_encoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753760e6-34ba-4341-82c1-06d3818a3c44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/99\n",
      "187/199\n",
      "277/299\n",
      "367/399\n",
      "458/499\n",
      "551/599\n",
      "648/699\n",
      "738/799\n",
      "828/899\n",
      "923/999\n",
      "accuracy is :  0.923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "You can now generate decoded sentences as such:\n",
    "\"\"\"\n",
    "match=0\n",
    "for seq_index in range(num_samples_test):\n",
    " \n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    # print(\"-\")\n",
    "    # print(\"Input sentence:\", functions[seq_index])\n",
    "    # print('actual is: ', derivatives[seq_index])\n",
    "    # print(\"Decoded sentence:\", decoded_sentence)\n",
    "    if(decoded_sentence.strip().replace('\\t','').replace('\\n','')\n",
    "       == str(derivatives[seq_index]).strip().replace('\\t','').replace('\\n','')):\n",
    "        match += 1\n",
    "    if((seq_index+1)%100==0):\n",
    "        print(str(match)+'/'+str(seq_index+1))\n",
    "\n",
    "print(\"accuracy is : \",match/num_samples_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1a411-92c9-4117-9a8d-0c969a5aeb77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}